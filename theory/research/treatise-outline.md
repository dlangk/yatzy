The Mathematics of Optimal YatzyFrom an 8-Megabyte Silicon Oracle to the Limits of Human CognitionTo a casual observer, Scandinavian Yatzy is a game of luck mitigated by intuition. You roll five dice, keep some, reroll the rest, and write a number on a scorecard.But to a computational mathematician, Yatzy is a perfectly engineered trap. It sits in a "Goldilocks zone" of complexity: its state space is exactly small enough to be solved to absolute mathematical perfection, yet its statistical properties—massive variance, discontinuous rewards, and deep sequential dependencies—make it phenomenally hostile to modern Artificial Intelligence. The same Deep Reinforcement Learning architectures that conquered Chess, Go, and Poker routinely crash and burn against five six-sided dice.Over the course of a massive computational study, we completely solved Scandinavian Yatzy. But building an 8-megabyte exact solver was only the beginning. By analyzing how the optimal strategy decays under compression, manipulating the thermodynamics of risk, and extracting human-readable heuristics, we mapped the exact boundary where mathematical truth meets human cognition.Here is the complete anatomy of optimal Yatzy.1. The Geometry of the GameNote: This study strictly analyzes Scandinavian Yatzy, which features 15 categories, a 50-point Upper Bonus, and scores lower-section patterns as the sum-of-dice. While the structural conclusions map to American Yahtzee, the exact scoring baselines differ.To solve a game, we must translate its physical components into a formal Markov Decision Process (MDP). In optimal control theory, a "state" must contain all historical information necessary to make the best possible future decision. Because the dice have no memory, the sequence of your past rolls is irrelevant. The only thing that dictates your future is your current scorecard.We encode a state $S = (C, m)$ using just two pieces of information:The Scored Categories ($C$): A 15-bit mask indicating which of the 15 categories are filled.The Upper Section Progress ($m$): An integer from 0 to 63 tracking the sum of Ones through Sixes (capped at 63, the threshold for the 50-point bonus).Multiplying these yields $2^{15} \times 64 = 2,097,152$ theoretical states. However, by running a reachability pass over the upper categories, we can prune mathematically impossible combinations (e.g., you cannot have an upper score of 63 if only the "Ones" category is filled). This reachability pruning collapses the game to exactly ~1.43 million reachable states.2. Engineering the Oracle: Backward InductionHow do you find the mathematically perfect move on Turn 1 when the consequences won't fully materialize until Turn 15? You cheat time. We start at the terminal states of the game and work backward using Backward Induction and the Bellman Equation.Because the game lacks hidden variables, we can cleanly isolate a single turn into a computational "Widget" containing 1,681 internal states. The widget alternates between Chance Nodes (rolling the dice, requiring a probability-weighted expected value summation) and Decision Nodes (keeping dice or choosing a category, requiring a Max operation).[CLAUDE: INSERT RUST PSEUDOCODE SNIPPET HERE - Show the structure of SOLVE_WIDGET and the ping-pong buffers used to evaluate the internal groups]Computing this Directed Acyclic Graph (DAG) efficiently requires extreme algorithmic engineering:Cache Alignment: We indexed states as C * 128 + m (using 128 as topological padding). This places all upper-score variants of a single scorecard sequentially in RAM, perfectly aligning with CPU L1/L2 cache lines during successor lookups.Ping-Pong Buffers: Memory is allocated per-widget (about 2 KB for temporary roll states) and freed instantly, with only the optimal turn-start Expected Value (EV) surviving to the persistent 8 MB table.Keep-Multiset Deduplication: A naive solver evaluates all 31 non-trivial positional bitmasks for a reroll. But positional masks are semantically aliased (Mask 01110 and 11100 both mean "Keep a triple" depending on how the dice are sorted). There are exactly 462 unique Keep-Multisets (combinations of 0 to 5 dice). By mapping masks to unique keeps, we stripped out ~47% of the sparse dot products in the inner loop.The result is the EV-Optimal Oracle. The absolute mathematical ceiling of Scandinavian Yatzy is exactly 248.4 Expected Points ($\sigma = 38.5$).3. The Anatomy of LuckAn Instructive Failure: The Max-PolicyTo understand why the dynamic programming solver is brilliant, we intentionally break it. If we replace the probability-weighted average at chance nodes with a pure maximum, we create the Max-Policy—an AI that assumes it has perfect dice luck.Under this assumption, the solver proudly outputs a precomputed expectation of 374 points (a mathematically perfect game). But when forced to play real, randomized games, its mean score collapses to an abysmal 118.7 points—worse than a human choosing actions entirely at random.Why it fails: The Max-Policy spreads overconfidence uniformly. On Turn 1, it keeps a single 6, assuming it will miraculously roll four more 6s for a Yatzy. It reaches Turn 15 having thrown away numerous guaranteed scores (like Straights) in pursuit of jackpots that never materialize.The Lesson: In sequential decision-making, uncertainty is not "noise" that blurs the optimal path; uncertainty is the signal that creates strategic depth. The need to hedge, build safety nets, and preserve Option Value only exists because of variance. The EV-optimal algorithm is smart specifically because it mathematically quantifies its own likelihood of failure.Score Densities: The Mixture of UniversesBecause optimal Yatzy relies on massive, discontinuous binary events (hitting the 50-point Bonus, hitting the 50-point Yatzy), the final score distribution violently violates the Central Limit Theorem.The score density is a Multimodal Mixture Distribution. The game fractures into four distinct Gaussian sub-populations based on the two major coin-flips:No Bonus, No Yatzy (Mean ~164)Yatzy, No Bonus (Mean ~213)Bonus, No Yatzy (Mean ~237)Bonus + Yatzy (Mean ~288)[CLAUDE: INSERT KDE DENSITY PLOT HERE - Visually decompose the overall bimodal density into the 4 sub-populations]Furthermore, optimal play creates Positive Covariance. Achieving the Upper Bonus correlates positively with the rest of the board. The mean score difference between bonus-hit and bonus-miss games is +72 points. Achieving the bonus doesn't just grant 50 points; it indicates a game state so mathematically healthy that the player generated an additional ~22 points of correlated improvement in the lower categories. Good games compound; bad games collapse.4. The Thermodynamics of Risk (The $\theta$ Parameter)Expected Value (EV) assumes you are playing an infinite number of solitaire games. But in a multiplayer tournament (a Winner-Take-All market), if you are trailing by 40 points entering Turn 13, playing for the highest "average" score is mathematically incorrect. Scoring 250 is functionally identical to scoring 0 if you need 260 to win.To model risk, we optimize for Exponential Utility: $U(x) = e^{\theta x}$.$\theta > 0$ (Risk-Seeking): The agent hunts extreme right-tail variance.$\theta < 0$ (Risk-Averse): The agent panics at zeros and locks in safe floors.Because exponential utility features Constant Absolute Risk Aversion (CARA), the "sunk score" mathematically factors out of the equation. We can map the entire frontier of human risk preferences using the exact same compressed 1.43M state space, avoiding a combinatorial explosion. To prevent floating-point overflow, chance nodes are computed in the log-domain using the Log-Sum-Exp (LSE) trick.The LSE Transition and the Mean-Variance FrontierThe transition from EV-optimal play to extreme risk is governed by a dimensionless control parameter: $|\theta| \cdot \sigma_{EV}$. This is mathematically identical to Free Energy in statistical mechanics, where $\theta$ acts as Inverse Temperature ($\beta$). As "temperature" drops, the system freezes into its ground states.[CLAUDE: INSERT MEAN-VARIANCE SCATTER PLOT HERE - Show the sideways 'V' or horseshoe shape formed by sweeping the theta parameter from -0.10 to +0.20]Sweeping $\theta$ reveals a stunning Mean-Variance Pareto Frontier:The Risk-Averse Branch: Hedging against dice is incredibly expensive. Dropping your variance slightly causes your expected mean to plummet. The bot strictly guards categories like Fives to guarantee the bonus.The Risk-Seeking Branch: Buying upside variance is remarkably cheap. Pushing $\theta$ slightly positive creates a "Hail Mary" policy that dramatically increases the frequency of 300+ point blowouts at an almost imperceptible cost to the global mean. It will intentionally leave Fives open, sacrificing guaranteed progression for a 1% lottery ticket at a Yatzy.5. Multiplayer Dynamics: The Adaptive EdgeCARA utility represents the absolute limit of what can be solved on the compressed 8 MB state space. However, true multiplayer Yatzy requires a Threshold Policy—maximizing the exact probability of beating an opponent's specific score.Against a static EV-optimal bot, a human is doomed. But what if we build an Optimally Adaptive Player that tracks the exact point differential ($m, C, x_{sunk}$) and dynamically shifts its risk posture?How much does the adaptive player win against a static EV bot? Roughly 53% to 55%.Despite perfect situational awareness, the overwhelming variance of the dice dilutes the strategic edge. The 3-5% win-rate delta comes almost entirely from two endgame maneuvers:The Hail Mary: Willingly incinerating safe EV to hunt a Yatzy, dropping your own absolute expected score just to maximize the probability of crossing the opponent's threshold.Taking a Knee: If you secure a lead late, you intentionally burn high-variance categories and bleed the clock, securing guaranteed low scores to mathematically eliminate the opponent's win condition.6. How Small Can a Yatzy Brain Be? (Compression)The exact Oracle requires an 8 MB lookup table. Can we compress it into a machine learning model using only the features visible during a real game?The Reinforcement Learning Chasm: Standard RL algorithms (which conquered Chess and Go) plateau around ~236 EV in Yatzy. They are defeated by three interacting barriers:The Discontinuous Value Cliff: The 50-point bonus triggers exactly at 63 points. Continuous neural networks blur this cliff, struggling to model the discontinuity without massive parameter bloat.The Signal-to-Noise Chasm: A brilliant sacrifice on Turn 3 gains +0.5 EV, but game-level noise is $\sigma = 38.5$. The true gradient is buried under stochastic noise.No Adversarial Curriculum: Yatzy is a solitaire fight against static mathematical variance; there is no self-play opponent to punish specific blind spots.Supervised Compression: By training directly on the Oracle's exact Q-values, we bypassed RL entirely:MLP Neural Networks: A tiny 5,000-parameter network achieves ~221 EV.Decision Trees: A depth-20 tree (~130K parameters, 500 KB) achieves 245 EV (just 3.4 points below optimal).[CLAUDE: INSERT PARAMETER VS EV LOSS GRAPH HERE - Plot the MLPs vs the DTs]Why do trees dominate neural networks here? Because optimal Yatzy strategy is piecewise-constant with hard, combinatorial boundaries. Decision trees handle axis-aligned step functions perfectly, whereas MLPs waste massive capacity learning soft approximations of math cliffs.The Irreducible Gap of the Long TailBy plotting EV loss against parameter count, we mapped the 80/20 rule of decisions. 80% of Yatzy decisions are "obvious" (large EV gaps between the best and second-best action). The remaining 20% form an incompressible long tail of micro-optimizations, where the difference between actions is $<0.05$ EV. Perfecting this tail requires an exponential explosion in parameters, because these edge cases depend on bizarre, non-linear interactions across the scorecard.7. Resource-Rationality and the Rosetta StoneHumans cannot memorize 130,000-node Decision Trees. We are Resource-Rational agents: we happily sacrifice the 3-point micro-optimization tail to massively reduce our cognitive load.To discover exactly how humans should play, we built a Zero-Hallucination Translation Compiler. We fed the 2-million-state Oracle into a Regret-Weighted Submodular Extraction loop, distilling the mathematics into a Semantic Decision List (IF-ELIF-ELSE rules).When we fed these raw boolean rules—along with their exact opportunity costs (regret_prevented)—into an LLM bound by a strict physics engine, it compiled the machine code into a Grandmaster Playbook. Just 100 lines of human-readable English text achieved an astonishing 227.5 EV.It revealed brilliant human heuristics invented purely by math:Slam the Straights: Fixed-value variance sinks. Take them instantly to prevent losing ~17.8 EV vs alternatives.Yatzy Supremacy: A 50-point Yatzy crushes almost all alternatives. Even placing five 6s in the Sixes box is mathematically inferior to taking the Yatzy, because keeping the Yatzy box open as a "lottery ticket" has immense Option Value.Upper Quad Protocol: 4-of-a-kind in high numbers strictly routes to the Upper Section to guarantee the 50-point cliff, bypassing the flat 24-point lower box.Garbage Routing: The "Option Value" of dead states. 1s and 2s are preserved purely to act as variance-absorbing garbage dumps for late-game disasters.Action Aliasing and Composable Filter GrammarsWhile Category Selection compressed beautifully to language, Reroll Selection initially crashed our pipeline, capping out at 184.4 EV. Why? Because saying "Keep the Pair" means something entirely different when you have [2,2,4,5,6] versus [5,5,1,2,3]. Humans don't perceive dice as positional bitmasks (Action Space Aliasing).To solve this, we modeled human Gestalt Perception using a Composable Filter Grammar (CFG) (MaxGroup | Face(6) $\to$ "Keep the pair AND any 6s").[CLAUDE: INSERT PHASE 7 CFG RESULTS HERE - Detail the Lambda cognitive-penalty sweep. How much EV was recovered by composing visual atoms?]Even with composable logic, human language hits an Incompressibility Horizon. Category selection is Macro-topology; Rerolls are Variance Steering. You cannot compress a 252-branch probability integral into an English sentence.8. Mechanistic Interpretability: The Neural CartographyDo neural networks "think" like us? To answer this, we transitioned to Mechanistic Interpretability.We built a Bilinear Dual Encoder (Two-Tower Architecture). We compressed the Board States and the 462 possible Physical Actions (Kept Dice vectors) into the exact same 16-dimensional continuous latent space, predicting EV via their geometric dot-product. This mathematically forced the network to organize its latent space purely by Opportunity Cost.When we project this 16D space down to 2D using UMAP with a cosine metric, a stunning cartography of Yatzy emerges.[CLAUDE: INSERT THE 2x3 UMAP GRID HERE - Showing embeddings colored by Turn, Bonus Status, and Semantic Rule Clusters]We visually observe:The Phase Transition: The manifold literally fractures into disconnected continents based on the mathematical life or death of the 50-point bonus.The Entropy Funnel: Turn 1 states form a dense, undifferentiated central nucleus, shattering outward into distinct, isolated tendrils as the endgame variance collapses.The Semantic Archipelago: Without any human prompting or text labels, the neural network organically clustered the physical dice actions into our exact human heuristics (e.g., "Straight Draws" in one geometric island, "High-EV Hoarding" on a thermal gradient opposite "Low-Value Defensive" plays).The neural network literally reinvented human concepts through pure geometry.ConclusionScandinavian Yatzy is a masterpiece of game design hiding in plain sight. It is a perfectly constrained laboratory for decision-making under uncertainty.By pushing the game through the brutal sieve of exact Dynamic Programming, we didn't just find the highest expected score. We mapped the thermodynamics of risk, diagnosed the structural blindspots of modern Machine Learning, and proved that true intelligence is resource-rational. We proved that without variance, strategy is an illusion.Whether you are rolling dice at a kitchen table, training neural networks, or steering risk in a winner-take-all market, the ultimate separator of champions is knowing exactly which mathematical truths are worth memorizing, and which are safely left to the dice.
