  <section id="compression">
    <h2>How Small Can a Yatzy Brain Be?</h2>

    <p>The optimal solver uses an 8 MB lookup table &mdash; 2 million states, each storing a single float. But do you actually need all that information to play well? We trained small machine learning models to approximate the solver's decisions, using only the information visible during a game: the dice, which categories remain, the upper section progress, and the turn number.</p>

    <p>We tried <span class="concept" data-concept="decision-tree">decision trees</span> (DTs) at various depths and multi-layer perceptrons (MLPs) with different architectures, then played 10,000 games with each model to measure actual performance.</p>

    <!-- Chart 5: Surrogate Pareto -->
    <div class="chart-container" id="chart-surrogate-pareto">
      <div class="chart-title">Model Size vs Game Performance</div>
      <div id="chart-surrogate-pareto-svg"></div>
      <div class="chart-legend"></div>
      <p class="chart-caption">Each point is a trained model playing 10,000 games. The x-axis (log scale) shows total parameters; y-axis shows mean score. The shaded band marks typical human performance (220&ndash;230). Hover for detailed stats.</p>
    </div>

    <p>The results are striking. Decision trees dominate neural networks at every model size. A depth-10 DT with just 6,249 parameters scores 216 &mdash; entering the range of casual human players. A depth-15 DT with 81K parameters reaches 239, approaching expert territory. And a depth-20 DT with 413K parameters hits 245 &mdash; within 3 points of optimal.</p>

    <p>Why do decision trees win? Yatzy decisions are fundamentally combinatorial: the optimal action depends on discrete thresholds (do I have 3 fives? is the straight complete?) rather than smooth interpolation. Decision trees encode these thresholds natively, while neural networks must learn to approximate step functions with smooth activations &mdash; a much harder task.</p>

    <p>The bonus rate tells the story: the heuristic hits the upper bonus 1.2% of the time, the depth-10 DT hits it 54% of the time, and the depth-20 DT hits it 84% &mdash; nearly matching the optimal 87%. Learning to protect the bonus is the single most important skill, and decision trees learn it efficiently.</p>
  </section>

  <hr class="divider">
