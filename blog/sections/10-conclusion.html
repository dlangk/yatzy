  <section id="conclusion">
    <h2>What We Learned</h2>

    <p>Yatzy is a deceptively rich game. Despite having a compact state space and a fast exact solver, it exhibits complex emergent behavior: multimodal score distributions, asymmetric risk-reward tradeoffs, dominant binary strategic events (the upper bonus), and a surprising amenability to policy compression.</p>

    <p>The core insights:</p>

    <p>The <strong>upper section bonus</strong> dominates everything. It's a 50-point swing that occurs in 87% of optimal games but only 1.2% of heuristic games. Protecting the bonus is worth sacrificing 20+ points of immediate score. Any strategy that doesn't prioritize the bonus is fundamentally broken.</p>

    <p>The <strong>score distribution is a four-component mixture</strong> created by two approximately independent binary events: hitting the bonus and scoring a Yatzy. This isn't just a statistical curiosity &mdash; it's the structural explanation for why the distribution is non-Gaussian and why risk-averse strategies can protect the floor so cheaply.</p>

    <p><strong>Risk-aversion is nearly free; risk-seeking is expensive.</strong> A slight risk-averse tilt (&theta; = &minus;0.02) lifts your worst games by 4+ points while costing less than 1 point in mean. Risk-seeking strategies gain only 1&ndash;2 points at the ceiling while losing 10+ points in the mean.</p>

    <p><strong>Decision trees compress the policy efficiently.</strong> A 6,000-parameter decision tree plays at casual human level; an 80,000-parameter one approaches expert level. Neural networks require 2&ndash;3x more parameters for the same performance. The decisions are fundamentally combinatorial, not smooth.</p>

    <p>The full source code, including the Rust solver, simulation infrastructure, analytics pipeline, and all data used in this post, is available on <a href="https://github.com/dlangk/yatzy">GitHub</a>.</p>
  </section>
